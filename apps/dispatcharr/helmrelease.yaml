---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2beta2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app dispatcharr
  namespace: *app
spec:
  chart:
    spec:
      chart: app-template
      version: 4.6.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  interval: 5m
  releaseName: *app
  targetNamespace: *app
  values:
    defaultPodOptions:
      runtimeClassName: "nvidia-cdi"
    controllers:
      dispatcharr:
        type: statefulset
        containers:
          app:
            image:
              repository: ghcr.io/dispatcharr/dispatcharr
              tag: 0.17.0
            env:
              TZ: "Europe/Berlin"
              # DISPATCHARR_ENV: aio
              REDIS_HOST: "dispatcharr-redis.dispatcharr.svc.cluster.local"
              CELERY_BROKER_URL: "redis://dispatcharr-redis.dispatcharr.svc.cluster.local:6379/0"
              DISPATCHARR_LOG_LEVEL: info
              NVIDIA_VISIBLE_DEVICES: "all"
              NVIDIA_DRIVER_CAPABILITIES: "all"
            resources:
              requests:
                cpu: 500m
              limits:
                cpu: 5000m
                nvidia.com/gpu: 1
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /
                    port: &port 9191
                  initialDelaySeconds: 30
                  periodSeconds: 30
                  timeoutSeconds: 10
                  failureThreshold: 3
              readiness: *probes
              startup:
                enabled: false
            securityContext:
              capabilities:
                add:
                  - SYS_NICE
              allowPrivilegeEscalation: false
          celery:
            image:
              repository: ghcr.io/dispatcharr/dispatcharr
              tag: 0.17.0
            env:
              TZ: "Europe/Berlin"
              POSTGRES_HOST: "dispatcharr-postgres.dispatcharr.svc.cluster.local"
              POSTGRES_DB: "dispatcharr"
              POSTGRES_USER: "dispatch"
              POSTGRES_PASSWORD: "dispatch"
              REDIS_HOST: "dispatcharr-redis.dispatcharr.svc.cluster.local"
              CELERY_BROKER_URL: "redis://dispatcharr-redis.dispatcharr.svc.cluster.local:6379/0"
            command: [ "/bin/bash", "-c" ]
            args: [ "cd /app && nice -n 5 celery -A dispatcharr worker -l info" ]
            resources:
              requests:
                cpu: 500m
              limits:
                cpu: 2000m
            probes:
              liveness:
                enabled: false
              readiness:
                enabled: false
              startup:
                enabled: false
            securityContext:
              capabilities:
                add:
                  - SYS_NICE
              allowPrivilegeEscalation: false
          gluetun:
            dependsOn: app
            image:
              repository: ghcr.io/qdm12/gluetun
              tag: v3.41.0
            env:
              TZ: Europe/Berlin
              FIREWALL: on
              FIREWALL_INPUT_PORTS: 9191,9999
              VPN_TYPE: wireguard
              VPN_SERVICE_PROVIDER: mullvad
              SERVER_COUNTRIES: Germany
              UPDATER_PERIOD: 12h
              DOT: off
              DNS_ADDRESS: 192.168.178.91
              FIREWALL_OUTBOUND_SUBNETS: "192.168.178.91/32,10.43.0.0/16,10.42.0.0/16"
              HEALTH_SERVER_ADDRESS: "0.0.0.0:9999"
            envFrom:
              - secret: dispatcharr-vpn-config
            # Configure the container-specific securityContext
            securityContext:
              capabilities:
                add:
                  - NET_ADMIN
                  - SYS_MODULE
            lifecycle:
              postStart:
                exec:
                  command: [ "/bin/sh", "-c", "(ip rule del table 51820; ip -6 rule del table 51820) || true" ]
            probes:
              readiness:
                enabled: false
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  exec:
                    command:
                      - /gluetun-entrypoint
                      - healthcheck
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  timeoutSeconds: 5
                  failureThreshold: 5
              startup: *probes
      redis:
        type: deployment
        strategy: "RollingUpdate"
        containers:
          redis:
            image:
              repository: redis
              tag: latest
            env:
              TZ: "Europe/Berlin"
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  exec:
                    command: [ "redis-cli", "info", "|", "grep loading:", "|", "grep 0" ]
              readiness: *probes
              startup: *probes
      postgres:
        type: deployment
        strategy: "RollingUpdate"
        containers:
          postgres:
            image:
              repository: postgres
              tag: 17
            env:
              TZ: "Europe/Berlin"
              POSTGRES_DB: "dispatcharr"
              POSTGRES_USER: "dispatch"
              POSTGRES_PASSWORD: "dispatch"
    service:
      app:
        controller: *app
        ports:
          http:
            port: *port
      gluetun:
        controller: *app
        ports:
          http:
            port: 9999
      postgres:
        controller: postgres
        ports:
          http:
            port: 5432
      redis:
        controller: redis
        ports:
          http:
            port: 6379
    ingress:
      app:
        className: "nginx"
        annotations:
          kubernetes.io/tls-acme: "true"
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
          cert-manager.io/cluster-issuer: "letsencrypt"
          nginx.ingress.kubernetes.io/proxy-buffering: "off"
          nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
          nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
          nginx.ingress.kubernetes.io/websocket-services: "dispatcharr-app"
          nginx.ingress.kubernetes.io/proxy-body-size: "0"
          nginx.ingress.kubernetes.io/proxy-buffer-size: "32k"
          nginx.ingress.kubernetes.io/whitelist-source-range: "192.168.0.0/16,10.0.0.0/8"
        hosts:
          - host: &host dispatcharr.internal.tmem.de
            paths:
              - path: /
                service:
                  identifier: app
                  port: http
        tls:
          - hosts:
              - *host
            secretName: dispatcharr-tls
    persistence:
      data:
        existingClaim: dispatcharr-config-pvc
        advancedMounts:
          dispatcharr:
            app:
              - path: /data
      postgres:
        existingClaim: dispatcharr-db-pvc
        advancedMounts:
          postgres:
            postgres:
              - path: /var/lib/postgresql/
      logs:
        type: emptyDir
      tmp:
        type: emptyDir
      vpn-config:
        enabled: true
        type: secret
        name: dispatcharr-vpn-config
        advancedMounts:
          dispatcharr:
            gluetun:
              - path: /gluetun/wireguard/
